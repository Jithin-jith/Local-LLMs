# Local-LLMs
This repository contains implementations of how LLMs can be run locally using Ollama and LM Studio.

## What are Open LLM Models
Open LLM models are Large Language Models that are made publicly available, either fully open-source or with permissive licenses, allowing developers and organizations to:

- Use them for free (often commercially too)
- Fine-tune or adapt them for specific tasks
- Deploy them on their own hardware or in the cloud

## ğŸ§ª Use Cases of Open LLMs
- Fine-tuning for custom chatbots or agents
- Embedding in private/local applications
- Educational use and research
- Evaluating fairness, bias, safety, etc.
- Building domain-specific assistants

## ğŸ” What Makes an LLM â€œOpenâ€?
An LLM is generally considered open if it meets most of these criteria:

|Criteria                |	Description                                                             |
|------------------------|--------------------------------------------------------------------------|
|âœ… Weights Available    |	The trained model weights are freely downloadable                         |
|âœ… Open License |	License allows commercial use, fine-tuning, and redistribution |
|âœ… Code Access |	Training code, inference code, or config is shared|
|âŒ Not Hosted Online |	Doesnâ€™t require you to use the providerâ€™s API (unlike GPT-4, Claude, etc.) |

---

## âœ… Top Options for Running LLMs Locally
ğŸ§  1. Ollama
- URL: https://ollama.com
- Best for: Easiest local LLM setup with a CLI
- How it works: Pulls and runs models like llama3, mistral, gemma, phi3, etc.
- Pros:
    - One-line install
    - Offers advanced configuration options
    - Simple ollama run llama3 interface
    - GPU & CPU support
    - Mac, Linux, Windows (WSL)
- Cons:
    - Limited GUI; mainly CLI-based

ğŸ’» 2. LM Studio
- URL: https://lmstudio.ai
- Best for: GUI-based chat with local models
- Pros:
    - Chat interface like ChatGPT
    - Drag-and-drop model loading from Hugging Face
    - Works on CPU & GPU
    - Prompt templates, multi-turn chat
    - Beautiful interface
    - Easy to run and switch models
    - Great for non-technical users
- Cons:
    - Slightly higher memory usage

âš¡ 3. llama.cpp
- URL: https://github.com/ggerganov/llama.cpp
- Best for: Developers and CLI enthusiasts
- What it does: C++ implementation of LLaMA that runs on CPU/GPU using quantized models
- Use with: llama.cpp, text-generation-webui, koboldcpp, or ollama

---

## Licenses

### ğŸ” 1. MIT License (for software and models)

âœ… **Overview**:  
One of the most permissive open-source licenses.  
Commonly used in traditional software, and some LLMs (e.g., Phi-2, GPT4All UI).

ğŸ”“ **You Can**:
- Use for personal or commercial projects  
- Modify and redistribute freely  
- Use in proprietary software  

ğŸš« **You Must**:
- Include the original license and copyright  

âš ï¸ **No Restrictions On**:
- Commercialization, hosting, or redistribution  

âœ… **Best for**:  
Maximum flexibility; ideal if you want to build and sell apps

---

### ğŸ¦™ 2. LLaMA License (Meta's custom license for LLaMA 2/3)

ğŸ” **Overview**:  
Not open-source in the traditional (OSI) sense.  
Research or commercial use allowed with conditions.

ğŸ”“ **You Can**:
- Use LLaMA for research and commercial use (subject to terms)  
- Fine-tune and host the model  

ğŸš« **You Cannot**:
- Use it in products competing with Meta  
- Remove Meta branding  
- Redistribute weights in some cases (especially modified ones)  

ğŸ“ **You Must**:
- Agree to Metaâ€™s Acceptable Use Policy (AUP) and license agreement  
- Not violate restrictions like building harmful AI or competing products  

âœ… **Best for**:  
Research projects, startups, and companies that donâ€™t compete with Meta

---

### ğŸ§  3. Gemma License (Googleâ€™s license for Gemma)

ğŸ“œ **Officially**: "Gemma Community License"

ğŸ” **Overview**:  
Not open-source.  
Allows personal, research, and commercial use â€” with limitations.

ğŸ”“ **You Can**:
- Use Gemma for research and commercial use  
- Run locally or in the cloud  

ğŸš« **You Cannot**:
- Use Gemma to build or improve competing LLMs  
- Use for training new foundational models  
- Redistribute modified versions of the weights  

ğŸ“ **You Must**:
- Follow Googleâ€™s terms, including ethical usage and branding  

âœ… **Best for**:  
Developers and researchers who want to build apps or chatbots (but not base models)


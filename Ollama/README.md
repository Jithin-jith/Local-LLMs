# ğŸ§  What is Ollama?

**Ollama** is a powerful **command-line tool and runtime** that makes it super easy to run and manage large language models (LLMs) locally on your machine.

> Think of it like **Docker**, but for **LLMs**.

Instead of worrying about downloading weights, converting formats, setting up tokenizers, or writing inference code, **Ollama wraps all of that into a single smooth experience**.

---

# âœ… What Can You Do with Ollama?

- ğŸƒâ€â™‚ï¸ **Run models** like **LLaMA 2**, **Mistral**, **Gemma**, **Phi**, **Codellama**, **OpenHermes**, **Neural Chat**, and more **locally**.
- ğŸ§© **Customize models** using `Modelfiles`. - https://github.com/ollama/ollama/blob/main/docs/modelfile.md
- ğŸ’¬ **Chat** with models from your **terminal** or **build apps** using the **Ollama API**.
- ğŸ› ï¸ **Fine-tune** or **personalize** models.
